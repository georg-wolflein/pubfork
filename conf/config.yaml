defaults:
  - _self_
  - dataset@dataset: msk_categorical_weighted
  # - feature_extractor@model.feature_extractor: mnist
  # - classifier@model.classifier: linear
  # - optimizer@optimizer: adamw

settings:
  feature_dim: 768

name: experiment
project: pubfork
output_dir: /mnt/bulk/gwoelflein/georg-transformers/output
seed: 0 # leave empty to use random seed
dataset:
  # clini_tables: ["/mnt/bulk/gwoelflein/georg-transformers/metadata/MSKCC-BRCA-DX_Cohort_1_CLINI.xlsx"]
  # slide_tables: ["/mnt/bulk/gwoelflein/georg-transformers/metadata/MSKCC-BRCA-DX_SLIDE.csv"]
  # feature_dirs: ["/mnt/bulk/gwoelflein/georg-transformers/data/MSKCC-BRCA-DX_BATCH1/ctranspath"]
  # filename_col: FILENAME
  # patient_col: PATIENT
  # targets:
  #   - column: HER2_3groups
  #     type: categorical
  #     classes: [HER2high, HER2low, HER2no]
  #     weights: # optional
  batch_size: 1
  instances_per_bag: 8192
  pad: False
  num_workers: 8
  choose_one_slide_per_patient: false
model:
  _target_: pubfork.model.MilTransformer
  d_features: 768
  targets: ${dataset.targets}
  agg: max # max, mean
  num_layers: 2
  num_heads: 4
  do_linear_proj: false
  do_initial_linear_proj: true
  hidden_dim: 256
  att_dropout: 0.3
  linear_dropout: 0.1
  add_zero_attn: false
  layer_norm: true
  mha1:
    _target_: pubfork.model.MultiheadAttention # pubfork.relative.DistanceAwareMultiheadAttention
    _partial_: true
    # embed_keys: true
    # embed_queries: false
    # embed_values: false
    # trainable_embeddings: true
    # num_embeddings: 10
    # dropout: 0.1
learning_rate: 1e-4
early_stopping:
  metric: val/${dataset.targets[0].column}/auroc
  goal: max
  patience: 10
  enabled: false
restore_best_checkpoint: true
max_epochs: 15
accumulate_grad_samples: 16
grad_clip: .5
device: # leave empty to use 1 GPU